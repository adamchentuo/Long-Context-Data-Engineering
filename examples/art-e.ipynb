{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adamchentuo/Long-Context-Data-Engineering/blob/main/examples/art-e.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zONEdDnpKBJm"
      },
      "source": [
        "To train this email search agent, click _Runtime_ and press _Run all_. Make sure you've enabled a free Tesla T4 GPU!\n",
        "\n",
        "<div class=\"align-center\">\n",
        "<a href=\"https://github.com/openpipe/art\"><img src=\"https://github.com/openpipe/art/raw/main/assets/ART_pill.png\" height=\"50\"></a>\n",
        "<a href=\"https://discord.gg/zbBHRUpwf4\"><img src=\"https://github.com/openpipe/art/raw/main/assets/Discord_pill.png\" height=\"50\"></a>\n",
        "<a href=\"https://art.openpipe.ai\"><img src=\"https://github.com/openpipe/art/raw/main/assets/Documentation_pill.png\" height=\"50\"></a>\n",
        "\n",
        "Questions? Join the Discord and ask away! For feature requests or to leave a star, visit our [Github](https://github.com/openpipe/art).\n",
        "\n",
        "</div>\n",
        "\n",
        "<a href=\"https://art.openpipe.ai/\"><img src=\"https://github.com/openpipe/art/raw/main/assets/Header_separator.png\" height=\"5\"></a>\n",
        "\n",
        "**Email Search Agent**\n",
        "\n",
        "In this notebook, you will be using [ART](https://github.com/openpipe/art) to train your own ART•E agent from scratch! If you aren't familiar with ART•E, you can learn more about it in the [blog post](https://openpipe.ai/blog/art-e-mail-agent).\n",
        "\n",
        "Beginning with a Qwen 2.5 7B base model, you will train it to search through emails and answer questions about them. You will learn how to construct an [agentic environment](#Environment), how to define a [rollout](#Rollout), and how to run a [training loop](#Loop). You will also learn how to use [RULER](#ruler) to judge the quality of the agent's answers.\n",
        "\n",
        "**RULER**\n",
        "\n",
        "RULER is a robust technique for evaluating the quality of an agent's answers and training the agent to produce more of its best completions. To learn more about RULER, see the [RULER documentation](https://art.openpipe.ai/fundamentals/ruler).\n",
        "\n",
        "Now let's get started!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGwDiiSKKBJq"
      },
      "source": [
        "### Installation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8R0M0OJTKBJq"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!uv pip install openpipe-art==0.3.11.post5 langchain-core tenacity datasets \"gql<4\" --prerelease allow --no-cache-dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7Mv3bQsKBJs"
      },
      "source": [
        "<a name=\"Environment-Variables\"></a>\n",
        "\n",
        "### Environment Variables\n",
        "\n",
        "**OpenAI (used for RULER judge model)**\n",
        "\n",
        "Our RULER reward function queries third-party models to judge the quality of the agent's performance. Any model supported by LiteLLM works. For this example we'll use OpenAI's o4-mini model, so we'll need to set the `OPENAI_API_KEY` environment variable.\n",
        "\n",
        "**Weights & Biases (optional)**\n",
        "\n",
        "Later on in the notebook, we'll be creating a model that can automatically logs metrics to Weights & Biases and chat completions to Weave. In order to do so, you'll need to provide your Weights & Biases API key as an environment variable.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "I33MpTGeKBJs",
        "outputId": "c3131ca0-b4f7-43d6-a2a9-3cdaa23a7c34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "OPENAI_API_KEY is required for RULER functionality when using openai/o4-mini.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4120627095.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;34m\"OPENAI_API_KEY is required for RULER functionality when using openai/o4-mini.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: OPENAI_API_KEY is required for RULER functionality when using openai/o4-mini."
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Required\n",
        "# os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\"\n",
        "\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "    raise ValueError(\n",
        "        \"OPENAI_API_KEY is required for RULER functionality when using openai/o4-mini.\"\n",
        "    )\n",
        "\n",
        "# Optional\n",
        "# os.environ[\"WANDB_API_KEY\"] = \"YOUR_API_KEY\"\n",
        "\n",
        "if not os.environ.get(\"WANDB_API_KEY\"):\n",
        "    print(\"WANDB_API_KEY is not set. We'll skip logging metrics to Weights & Biases.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6UjTaevKBJs"
      },
      "source": [
        "<a name=\"Environment\"></a>\n",
        "\n",
        "### 电子邮件搜索环境\n",
        "ART 允许您的代理通过与环境的交互来学习。在这个例子中，我们将创建一个环境，使代理能够搜索电子邮件并回答有关电子邮件的问题。\n",
        "\n",
        "代理将可以使用三个工具：\n",
        "\n",
        "search_inbox - 通过关键词搜索电子邮件\n",
        "read_email - 通过消息 ID 读取特定电子邮件\n",
        "return_final_answer - 返回最终答案，并附上源电子邮件 ID\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "N-3S9Cw5KBJt",
        "outputId": "7bf7453b-2fd5-410d-a25e-ad22dd8e4648",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556,
          "referenced_widgets": [
            "58fdaec5ad8745929830387d20e8397e",
            "51dd537611d4445b88d139b66fe2c4a2",
            "00d7f424a59349fb8d8fe0bcf0bd7102",
            "cc4430035a0545c9a800db300d91a174",
            "3d09c6c630484dec915552689ba69663",
            "54c0e051ce1f4fd6972ebdfe4e8ae08d",
            "e97ba0da9e334134a979be6972b41a04",
            "d62dea2c92534b63b0df7a91b6680d63",
            "69e9984702ff4cceb6c7cd55edf38860",
            "65a7f6895ffa4174831c9fc2063b24ed",
            "f22b78db8a3c422b836f4f443c81f6a5",
            "d9e872fa3ca14db9bca2463bdca3b41f",
            "cad5bee991074396a6cfc434500ebd91",
            "d0022cb132e4474c8e40aaadfd71fb3c",
            "f991f8de175c46c0ac25fbef442c4c98",
            "4f1c119128644809a2f9fd92c824a383",
            "271cd7d4207340e4938b3ee12e889add",
            "b763df2591004561ad582d7b00feb6f4",
            "117b3eadcd78492085a37b821dd64579",
            "55c5fae124154ed68bb64d7023032604",
            "402f5ace992147b0a09e21e122a0609d",
            "f9a2416c5bf44d1b938a44eb52874f5a",
            "80a8753a4ce74f4e8cbc419dd2b4cfb5",
            "b986665f2a424a399bdc50c5a1d6f9a2",
            "6294c4d7db0c4446bfbe870b1fb00663",
            "34ebb3bd161c400b8686b166838de5fa",
            "c640c8620bb244708a5f26423059de6b",
            "94fdc195922643759f0cdd589d6fec60",
            "d463ac615ede4edb8eb9ec83746f66da",
            "02b2e89be06c40e79024dc8a88272d19",
            "b2ea09cf684944cf83dd980105a13518",
            "8fb55d6ec4774e698ef689711e3fe394",
            "b53c2a30d50b4fea9b8fa9cb443f669c",
            "d654feb8c837413d9e2eed3d0c05c29e",
            "2d725e8f396943919db3132bc4f0dcd4",
            "acbff660bb2c4ce3bfbea69736c520c8",
            "8d14909d1bd04100ae917ba0bb938597",
            "0872d4d7e6074875983ce1e6f16e02db",
            "292ddab707b6473795ab6e0471da4ad4",
            "7e4ea1fb7d8b431b97b67bf31e9fa639",
            "c4d214dbbd8a41bda05094c0a7a840bb",
            "b822452a3aca49f1825569859a69d684",
            "d88ec76b677143d48fd043183d6a34ae",
            "56256df39f0349868d36bfc56eebf065",
            "afab869005ee43cebe5c509ca96e3102",
            "cdfa9c8b41db4196adf6c160479cd307",
            "b35821ae04964dc1991c1ca8dd1b888b",
            "b2289aa5d03a4e02984b00917fde90ad",
            "2fc3e08aa6394355a22d600d1fc28d9b",
            "023c6b7d19564faa84a9fd572ad0e98c",
            "a65e7289aec743a4ab276127421f64dd",
            "0a6300db73444b1e8965fd01465ccc51",
            "7896eb432ed445cfb93f3633058ebe63",
            "3e95330d012f4717b66331d4dbf212e7",
            "6c3a9ceb5d994e1ba844743767387f37",
            "5422e8503d18440d908b78774f6d5100",
            "1298ae38917943049faef93c825f3023",
            "4acd820779de427a8b85a41987d813e5",
            "c94d4039ea0b4195964d90cef0ecda3e",
            "e3c358c0690b45118b84d0e5c13634a1",
            "f885b1d9df4b4c13876c5520756c0e9b",
            "13bb10e53c124257ac90f6da4cf1b569",
            "4828d19db19b448b87cebf2e79722c9f",
            "6c1f31583c54400fb00ebfb2494f3389",
            "58ce69dd46a648bb9d0e763a62175cc6",
            "cf906ce5311e4859af04a2965f453e13"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading train scenarios from Hugging Face...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/631 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "58fdaec5ad8745929830387d20e8397e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/681k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9e872fa3ca14db9bca2463bdca3b41f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/268k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80a8753a4ce74f4e8cbc419dd2b4cfb5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/4390 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d654feb8c837413d9e2eed3d0c05c29e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/1733 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "afab869005ee43cebe5c509ca96e3102"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/4390 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5422e8503d18440d908b78774f6d5100"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 50 scenarios.\n",
            "Email search environment created with full Enron dataset!\n",
            "Database contains the complete email dataset, loaded 50 training scenarios.\n",
            "\n",
            "Sample scenario\n",
            "id: 3296\n",
            "question: Who can I contact for Power Operations when Sally is in London?\n",
            "answer: Stacey White (x31870) and Leslie Reeves (x37962).\n",
            "message_ids: ['<6033065.1075856098960.JavaMail.evans@thyme>']\n",
            "how_realistic: 0.699999988079071\n",
            "inbox_address: louise.kitchen@enron.com\n",
            "query_date: 2001-01-25\n",
            "split: train\n"
          ]
        }
      ],
      "source": [
        "import sqlite3\n",
        "import random\n",
        "import os\n",
        "from typing import List, Optional, Literal\n",
        "from dataclasses import dataclass, asdict\n",
        "from pydantic import BaseModel, Field\n",
        "from textwrap import dedent\n",
        "from datasets import load_dataset, Dataset, Features, Value, Sequence\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "import json\n",
        "\n",
        "\n",
        "# Email and Scenario data models\n",
        "class Email(BaseModel):\n",
        "    message_id: str\n",
        "    date: str  # ISO 8601 string 'YYYY-MM-DD HH:MM:SS'\n",
        "    subject: Optional[str] = None\n",
        "    from_address: Optional[str] = None\n",
        "    to_addresses: List[str] = []  # Populated from recipients table\n",
        "    cc_addresses: List[str] = []  # Populated from recipients table\n",
        "    bcc_addresses: List[str] = []  # Populated from recipients table\n",
        "    body: Optional[str] = None\n",
        "    file_name: Optional[str] = None\n",
        "\n",
        "\n",
        "class Scenario(BaseModel):\n",
        "    id: int\n",
        "    question: str\n",
        "    answer: str\n",
        "    message_ids: List[str]  # message_ids (strings) of referenced emails\n",
        "    how_realistic: float\n",
        "    inbox_address: str\n",
        "    query_date: str\n",
        "    split: Literal[\"train\", \"test\"]\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class SearchResult:\n",
        "    message_id: str\n",
        "    snippet: str\n",
        "\n",
        "\n",
        "class FinalAnswer(BaseModel):\n",
        "    answer: str\n",
        "    source_ids: list[str]\n",
        "\n",
        "\n",
        "# Database configuration\n",
        "DB_PATH = \"./enron_emails.db\"\n",
        "EMAIL_DATASET_REPO_ID = \"corbt/enron-emails\"\n",
        "SCENARIO_DATASET_REPO_ID = \"corbt/enron_emails_sample_questions\"\n",
        "\n",
        "# Global database connection\n",
        "db_conn = None\n",
        "\n",
        "\n",
        "def create_email_database():\n",
        "    \"\"\"Create the email database from Hugging Face dataset\"\"\"\n",
        "    print(\"Creating email database from Hugging Face dataset...\")\n",
        "    print(\n",
        "        \"This will download and process the full Enron email dataset - this may take several minutes...\"\n",
        "    )\n",
        "\n",
        "    # Database schema\n",
        "    SQL_CREATE_TABLES = \"\"\"\n",
        "    DROP TABLE IF EXISTS recipients;\n",
        "    DROP TABLE IF EXISTS emails_fts;\n",
        "    DROP TABLE IF EXISTS emails;\n",
        "\n",
        "    CREATE TABLE emails (\n",
        "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "        message_id TEXT UNIQUE,\n",
        "        subject TEXT,\n",
        "        from_address TEXT,\n",
        "        date TEXT,\n",
        "        body TEXT,\n",
        "        file_name TEXT\n",
        "    );\n",
        "\n",
        "    CREATE TABLE recipients (\n",
        "        email_id TEXT,\n",
        "        recipient_address TEXT,\n",
        "        recipient_type TEXT\n",
        "    );\n",
        "    \"\"\"\n",
        "\n",
        "    SQL_CREATE_INDEXES_TRIGGERS = \"\"\"\n",
        "    CREATE INDEX idx_emails_from ON emails(from_address);\n",
        "    CREATE INDEX idx_emails_date ON emails(date);\n",
        "    CREATE INDEX idx_emails_message_id ON emails(message_id);\n",
        "    CREATE INDEX idx_recipients_address ON recipients(recipient_address);\n",
        "    CREATE INDEX idx_recipients_type ON recipients(recipient_type);\n",
        "    CREATE INDEX idx_recipients_email_id ON recipients(email_id);\n",
        "    CREATE INDEX idx_recipients_address_email ON recipients(recipient_address, email_id);\n",
        "\n",
        "    CREATE VIRTUAL TABLE emails_fts USING fts5(\n",
        "        subject,\n",
        "        body,\n",
        "        content='emails',\n",
        "        content_rowid='id'\n",
        "    );\n",
        "\n",
        "    CREATE TRIGGER emails_ai AFTER INSERT ON emails BEGIN\n",
        "        INSERT INTO emails_fts (rowid, subject, body)\n",
        "        VALUES (new.id, new.subject, new.body);\n",
        "    END;\n",
        "\n",
        "    CREATE TRIGGER emails_ad AFTER DELETE ON emails BEGIN\n",
        "        DELETE FROM emails_fts WHERE rowid=old.id;\n",
        "    END;\n",
        "\n",
        "    CREATE TRIGGER emails_au AFTER UPDATE ON emails BEGIN\n",
        "        UPDATE emails_fts SET subject=new.subject, body=new.body WHERE rowid=old.id;\n",
        "    END;\n",
        "    \"\"\"\n",
        "\n",
        "    # Create database\n",
        "    conn = sqlite3.connect(DB_PATH)\n",
        "    cursor = conn.cursor()\n",
        "    cursor.executescript(SQL_CREATE_TABLES)\n",
        "    conn.commit()\n",
        "\n",
        "    # Load dataset\n",
        "    print(\"Loading full email dataset...\")\n",
        "    expected_features = Features(\n",
        "        {\n",
        "            \"message_id\": Value(\"string\"),\n",
        "            \"subject\": Value(\"string\"),\n",
        "            \"from\": Value(\"string\"),\n",
        "            \"to\": Sequence(Value(\"string\")),\n",
        "            \"cc\": Sequence(Value(\"string\")),\n",
        "            \"bcc\": Sequence(Value(\"string\")),\n",
        "            \"date\": Value(\"timestamp[us]\"),\n",
        "            \"body\": Value(\"string\"),\n",
        "            \"file_name\": Value(\"string\"),\n",
        "        }\n",
        "    )\n",
        "\n",
        "    dataset = load_dataset(\n",
        "        EMAIL_DATASET_REPO_ID, features=expected_features, split=\"train\"\n",
        "    )\n",
        "    print(f\"Dataset contains {len(dataset)} total emails\")\n",
        "\n",
        "    # Populate database with ALL emails (not limited to 1000)\n",
        "    print(\"Populating database with all emails...\")\n",
        "    conn.execute(\"PRAGMA synchronous = OFF;\")\n",
        "    conn.execute(\"PRAGMA journal_mode = MEMORY;\")\n",
        "    conn.execute(\"BEGIN TRANSACTION;\")\n",
        "\n",
        "    record_count = 0\n",
        "    skipped_count = 0\n",
        "    duplicate_count = 0\n",
        "    processed_emails = set()  # Track (subject, body, from) tuples for deduplication\n",
        "\n",
        "    for email_data in tqdm(dataset, desc=\"Inserting emails\"):\n",
        "        message_id = email_data[\"message_id\"]\n",
        "        subject = email_data[\"subject\"]\n",
        "        from_address = email_data[\"from\"]\n",
        "        date_obj: datetime = email_data[\"date\"]\n",
        "        body = email_data[\"body\"]\n",
        "        file_name = email_data[\"file_name\"]\n",
        "        to_list = [str(addr) for addr in email_data[\"to\"] if addr]\n",
        "        cc_list = [str(addr) for addr in email_data[\"cc\"] if addr]\n",
        "        bcc_list = [str(addr) for addr in email_data[\"bcc\"] if addr]\n",
        "\n",
        "        # Apply the same filters as the original project\n",
        "        total_recipients = len(to_list) + len(cc_list) + len(bcc_list)\n",
        "\n",
        "        # Filter out very long emails and those with too many recipients\n",
        "        if len(body) > 5000:\n",
        "            skipped_count += 1\n",
        "            continue\n",
        "\n",
        "        if total_recipients > 30:\n",
        "            skipped_count += 1\n",
        "            continue\n",
        "\n",
        "        # Deduplication check (same as original project)\n",
        "        email_key = (subject, body, from_address)\n",
        "        if email_key in processed_emails:\n",
        "            duplicate_count += 1\n",
        "            continue\n",
        "        else:\n",
        "            processed_emails.add(email_key)\n",
        "\n",
        "        date_str = date_obj.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "        cursor.execute(\n",
        "            \"\"\"\n",
        "            INSERT INTO emails (message_id, subject, from_address, date, body, file_name)\n",
        "            VALUES (?, ?, ?, ?, ?, ?)\n",
        "        \"\"\",\n",
        "            (message_id, subject, from_address, date_str, body, file_name),\n",
        "        )\n",
        "\n",
        "        # Insert recipients\n",
        "        recipient_data = []\n",
        "        for addr in to_list:\n",
        "            recipient_data.append((message_id, addr, \"to\"))\n",
        "        for addr in cc_list:\n",
        "            recipient_data.append((message_id, addr, \"cc\"))\n",
        "        for addr in bcc_list:\n",
        "            recipient_data.append((message_id, addr, \"bcc\"))\n",
        "\n",
        "        if recipient_data:\n",
        "            cursor.executemany(\n",
        "                \"\"\"\n",
        "                INSERT INTO recipients (email_id, recipient_address, recipient_type)\n",
        "                VALUES (?, ?, ?)\n",
        "            \"\"\",\n",
        "                recipient_data,\n",
        "            )\n",
        "\n",
        "        record_count += 1\n",
        "\n",
        "    conn.commit()\n",
        "\n",
        "    # Create indexes and triggers\n",
        "    print(\"Creating indexes and FTS...\")\n",
        "    cursor.executescript(SQL_CREATE_INDEXES_TRIGGERS)\n",
        "    cursor.execute('INSERT INTO emails_fts(emails_fts) VALUES(\"rebuild\")')\n",
        "    conn.commit()\n",
        "\n",
        "    print(f\"Successfully created database with {record_count} emails.\")\n",
        "    print(f\"Skipped {skipped_count} emails due to length/recipient limits.\")\n",
        "    print(f\"Skipped {duplicate_count} duplicate emails.\")\n",
        "    return conn\n",
        "\n",
        "\n",
        "def get_db_connection():\n",
        "    \"\"\"Get database connection\"\"\"\n",
        "    global db_conn\n",
        "    if db_conn is None:\n",
        "        if os.path.exists(DB_PATH):\n",
        "            print(f\"Loading existing database from {DB_PATH}\")\n",
        "            db_conn = sqlite3.connect(DB_PATH, check_same_thread=False)\n",
        "        else:\n",
        "            db_conn = create_email_database()\n",
        "    return db_conn\n",
        "\n",
        "\n",
        "def search_emails(\n",
        "    inbox: str,\n",
        "    keywords: List[str],\n",
        "    from_addr: Optional[str] = None,\n",
        "    to_addr: Optional[str] = None,\n",
        "    sent_after: Optional[str] = None,\n",
        "    sent_before: Optional[str] = None,\n",
        "    max_results: int = 10,\n",
        ") -> List[SearchResult]:\n",
        "    \"\"\"Search the email database based on keywords and filters\"\"\"\n",
        "    conn = get_db_connection()\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    where_clauses: List[str] = []\n",
        "    params: List[str | int] = []\n",
        "\n",
        "    if not keywords:\n",
        "        raise ValueError(\"No keywords provided for search.\")\n",
        "\n",
        "    if max_results > 10:\n",
        "        raise ValueError(\"max_results must be less than or equal to 10.\")\n",
        "\n",
        "    # FTS5 default is AND, so just join keywords. Escape quotes for safety.\n",
        "    fts_query = \" \".join(f\"\"\" \"{k.replace('\"', '\"\"')}\" \"\"\" for k in keywords)\n",
        "    where_clauses.append(\"fts.emails_fts MATCH ?\")\n",
        "    params.append(fts_query)\n",
        "\n",
        "    # Inbox filter\n",
        "    where_clauses.append(\"\"\"\n",
        "        (e.from_address = ? OR EXISTS (\n",
        "            SELECT 1 FROM recipients r_inbox\n",
        "            WHERE r_inbox.recipient_address = ? AND r_inbox.email_id = e.message_id\n",
        "        ))\n",
        "    \"\"\")\n",
        "    params.extend([inbox, inbox])\n",
        "\n",
        "    if from_addr:\n",
        "        where_clauses.append(\"e.from_address = ?\")\n",
        "        params.append(from_addr)\n",
        "\n",
        "    if to_addr:\n",
        "        where_clauses.append(\"\"\"\n",
        "            EXISTS (\n",
        "                SELECT 1 FROM recipients r_to\n",
        "                WHERE r_to.recipient_address = ? AND r_to.email_id = e.message_id\n",
        "            )\n",
        "        \"\"\")\n",
        "        params.append(to_addr)\n",
        "\n",
        "    if sent_after:\n",
        "        where_clauses.append(\"e.date >= ?\")\n",
        "        params.append(f\"{sent_after} 00:00:00\")\n",
        "\n",
        "    if sent_before:\n",
        "        where_clauses.append(\"e.date < ?\")\n",
        "        params.append(f\"{sent_before} 00:00:00\")\n",
        "\n",
        "    sql = f\"\"\"\n",
        "        SELECT\n",
        "            e.message_id,\n",
        "            snippet(emails_fts, -1, '<b>', '</b>', ' ... ', 15) as snippet\n",
        "        FROM\n",
        "            emails e JOIN emails_fts fts ON e.id = fts.rowid\n",
        "        WHERE\n",
        "            {\" AND \".join(where_clauses)}\n",
        "        ORDER BY\n",
        "            e.date DESC\n",
        "        LIMIT ?;\n",
        "    \"\"\"\n",
        "    params.append(max_results)\n",
        "\n",
        "    cursor.execute(sql, params)\n",
        "    results = cursor.fetchall()\n",
        "\n",
        "    return [SearchResult(message_id=row[0], snippet=row[1]) for row in results]\n",
        "\n",
        "\n",
        "def read_email(message_id: str) -> Optional[Email]:\n",
        "    \"\"\"Retrieve a single email by its message_id\"\"\"\n",
        "    conn = get_db_connection()\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # Get email details\n",
        "    cursor.execute(\n",
        "        \"SELECT message_id, date, subject, from_address, body, file_name FROM emails WHERE message_id = ?\",\n",
        "        (message_id,),\n",
        "    )\n",
        "    email_row = cursor.fetchone()\n",
        "\n",
        "    if not email_row:\n",
        "        return None\n",
        "\n",
        "    msg_id, date, subject, from_addr, body, file_name = email_row\n",
        "\n",
        "    # Get recipients\n",
        "    cursor.execute(\n",
        "        \"SELECT recipient_address, recipient_type FROM recipients WHERE email_id = ?\",\n",
        "        (message_id,),\n",
        "    )\n",
        "    recipient_rows = cursor.fetchall()\n",
        "\n",
        "    to_addresses = []\n",
        "    cc_addresses = []\n",
        "    bcc_addresses = []\n",
        "\n",
        "    for addr, type_val in recipient_rows:\n",
        "        if type_val.lower() == \"to\":\n",
        "            to_addresses.append(addr)\n",
        "        elif type_val.lower() == \"cc\":\n",
        "            cc_addresses.append(addr)\n",
        "        elif type_val.lower() == \"bcc\":\n",
        "            bcc_addresses.append(addr)\n",
        "\n",
        "    return Email(\n",
        "        message_id=msg_id,\n",
        "        date=date,\n",
        "        subject=subject,\n",
        "        from_address=from_addr,\n",
        "        to_addresses=to_addresses,\n",
        "        cc_addresses=cc_addresses,\n",
        "        bcc_addresses=bcc_addresses,\n",
        "        body=body,\n",
        "        file_name=file_name,\n",
        "    )\n",
        "\n",
        "\n",
        "def load_training_scenarios(\n",
        "    split: Literal[\"train\", \"test\"] = \"train\",\n",
        "    limit: Optional[int] = None,\n",
        "    max_messages: Optional[int] = 1,\n",
        "    shuffle: bool = False,\n",
        "    seed: Optional[int] = None,\n",
        ") -> List[Scenario]:\n",
        "    \"\"\"Load training scenarios from Hugging Face dataset\"\"\"\n",
        "    print(f\"Loading {split} scenarios from Hugging Face...\")\n",
        "    dataset: Dataset = load_dataset(SCENARIO_DATASET_REPO_ID, split=split)\n",
        "\n",
        "    if max_messages is not None:\n",
        "        dataset = dataset.filter(lambda x: len(x[\"message_ids\"]) <= max_messages)\n",
        "\n",
        "    if shuffle or (seed is not None):\n",
        "        if seed is not None:\n",
        "            dataset = dataset.shuffle(seed=seed)\n",
        "        else:\n",
        "            dataset = dataset.shuffle()\n",
        "\n",
        "    # Convert each row to a Scenario object\n",
        "    scenarios = [Scenario(**row, split=split) for row in dataset]\n",
        "\n",
        "    if max_messages is not None:\n",
        "        scenarios = [s for s in scenarios if len(s.message_ids) <= max_messages]\n",
        "\n",
        "    if shuffle:\n",
        "        if seed is not None:\n",
        "            rng = random.Random(seed)\n",
        "            rng.shuffle(scenarios)\n",
        "        else:\n",
        "            random.shuffle(scenarios)\n",
        "\n",
        "    if limit is not None:\n",
        "        scenarios = scenarios[:limit]\n",
        "\n",
        "    print(f\"Loaded {len(scenarios)} scenarios.\")\n",
        "    return scenarios\n",
        "\n",
        "\n",
        "# Load training scenarios\n",
        "training_scenarios = load_training_scenarios(\n",
        "    split=\"train\", limit=50, max_messages=1, shuffle=True, seed=42\n",
        ")\n",
        "\n",
        "print(\"Email search environment created with full Enron dataset!\")\n",
        "print(\n",
        "    f\"Database contains the complete email dataset, loaded {len(training_scenarios)} training scenarios.\"\n",
        ")\n",
        "\n",
        "# print first scenario\n",
        "print(\"\\nSample scenario\")\n",
        "print(\"id:\", training_scenarios[0].id)\n",
        "print(\"question:\", training_scenarios[0].question)\n",
        "print(\"answer:\", training_scenarios[0].answer)\n",
        "print(\"message_ids:\", training_scenarios[0].message_ids)\n",
        "print(\"how_realistic:\", training_scenarios[0].how_realistic)\n",
        "print(\"inbox_address:\", training_scenarios[0].inbox_address)\n",
        "print(\"query_date:\", training_scenarios[0].query_date)\n",
        "print(\"split:\", training_scenarios[0].split)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SJRMb5TKBJv"
      },
      "source": [
        "### 创建模型\n",
        "现在我们已经定义了环境的规则，我们可以创建一个模型，该模型将学习有效地搜索电子邮件。我们将使用Qwen 2.5 7B模型进行此示例。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mQLhpi04KBJw",
        "outputId": "d34415e9-2386-433d-a4b4-e82cd9c58fd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 08-06 02:22:12 [importing.py:53] Triton module has been replaced with a placeholder.\n",
            "INFO 08-06 02:22:12 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform\n",
            "WARNING 08-06 02:22:14 [_custom_ops.py:21] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-544707715.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Register the model with the local Backend (sets up logging, inference, and training)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mawait\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/art/model.py\u001b[0m in \u001b[0;36mregister\u001b[0;34m(self, backend, _openai_client_config)\u001b[0m\n\u001b[1;32m    188\u001b[0m     ) -> None:\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mawait\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         base_url, api_key = await backend._prepare_backend_for_training(\n\u001b[0m\u001b[1;32m    191\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_openai_client_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/art/local/backend.py\u001b[0m in \u001b[0;36m_prepare_backend_for_training\u001b[0;34m(self, model, config)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpenAIServerConfig\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     ) -> tuple[str, str]:\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0mservice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_service\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0;32mawait\u001b[0m \u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_openai_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mserver_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"server_args\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/art/local/backend.py\u001b[0m in \u001b[0;36m_get_service\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_service\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainableModel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mModelService\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_services\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             config = dev.get_model_config(\n\u001b[0m\u001b[1;32m    112\u001b[0m                 \u001b[0mbase_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_model_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mart_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/art/dev/model.py\u001b[0m in \u001b[0;36mget_model_config\u001b[0;34m(base_model, output_dir, config)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# Multi-step processing is not supported for the Xformers attention backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# which is the fallback for devices with compute capability < 8.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mnum_scheduler_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device_capability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m8\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0menable_sleep_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menable_sleep_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mgeneration_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"vllm\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mget_device_capability\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmajor\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mminor\u001b[0m \u001b[0mcuda\u001b[0m \u001b[0mcapability\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m     \"\"\"\n\u001b[0;32m--> 507\u001b[0;31m     \u001b[0mprop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_device_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mget_device_properties\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0m_CudaDeviceProperties\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mproperties\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \"\"\"\n\u001b[0;32m--> 523\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# will define _get_device_properties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_device_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ],
      "source": [
        "import art\n",
        "from art.local import LocalBackend\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "# Declare the model\n",
        "model = art.TrainableModel(\n",
        "    name=\"email-agent-001\",\n",
        "    project=\"email-search-agent\",\n",
        "    base_model=\"Qwen/Qwen2.5-7B-Instruct\",\n",
        ")\n",
        "\n",
        "# To run on a T4, we need to override some config defaults.\n",
        "model._internal_config = art.dev.InternalModelConfig(\n",
        "    init_args=art.dev.InitArgs(\n",
        "        max_seq_length=8192,\n",
        "    ),\n",
        "    engine_args=art.dev.EngineArgs(\n",
        "        enforce_eager=True,\n",
        "        gpu_memory_utilization=0.8,\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Initialize the server\n",
        "backend = LocalBackend(\n",
        "    # Normally we don't want to run the server in-process, but for the output\n",
        "    # to show up properly on Google Colab we'll enable this.\n",
        "    in_process=True,\n",
        "    path=\"./.art\",\n",
        ")\n",
        "\n",
        "# Register the model with the local Backend (sets up logging, inference, and training)\n",
        "await model.register(backend)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ufk1SFdKBJw"
      },
      "source": [
        "<a name=\"Rollout\"></a>\n",
        "\n",
        "### Defining a Rollout\n",
        "\n",
        "A rollout is a single episode of an agent performing its task. In this example, the rollout function presents the agent with an email search scenario, and the agent uses the available tools to search for emails and answer the question.\n",
        "\n",
        "When the agent provides a final answer, the `correct` metric is calculated based on whether the answer is correct.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbTwQ83TKBJx"
      },
      "outputs": [],
      "source": [
        "import art\n",
        "import weave\n",
        "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
        "from tenacity import retry, stop_after_attempt\n",
        "from litellm import acompletion\n",
        "from art.utils.litellm import convert_litellm_choice_to_openai\n",
        "\n",
        "if os.getenv(\"WANDB_API_KEY\", \"\"):\n",
        "    weave.init(model.project, settings={\"print_call_link\": False})\n",
        "\n",
        "MAX_TURNS = 10\n",
        "\n",
        "\n",
        "class CorrectnessJudgeResponse(BaseModel):\n",
        "    reasoning: str = Field(description=\"Explanation of the reasoning process.\")\n",
        "    accept: bool = Field(description=\"Whether the AI answer should be accepted.\")\n",
        "\n",
        "\n",
        "@retry(stop=stop_after_attempt(3))\n",
        "async def judge_correctness(\n",
        "    scenario: Scenario, answer: str\n",
        ") -> CorrectnessJudgeResponse:\n",
        "    system_prompt = dedent(\n",
        "        \"\"\"\n",
        "        You are given a question, the reference answer (labelled **Reference answer**), and an answer generated by an AI assistant (labelled **AI answer**).\n",
        "\n",
        "        Your task is to decide whether the AI answer is correct and should be accepted. You should accept the answer if it contains the relevant information from the reference answer. You should not accept the answer if it is missing information relevant to the question, or if it contradicts the reference answer.\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": (\n",
        "                f\"Question: {scenario.question}\\n\"\n",
        "                f\"Reference answer: {scenario.answer}\\n\"\n",
        "                f\"AI answer: {answer}\"\n",
        "            ),\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    response = await acompletion(\n",
        "        model=\"openai/gpt-4.1\",\n",
        "        messages=messages,\n",
        "        response_format=CorrectnessJudgeResponse,\n",
        "    )\n",
        "\n",
        "    first_choice = response.choices[0]\n",
        "    raw_content = first_choice.message.content or \"{}\"\n",
        "\n",
        "    try:\n",
        "        return CorrectnessJudgeResponse.model_validate_json(raw_content)\n",
        "    except Exception as e:\n",
        "        return CorrectnessJudgeResponse(\n",
        "            reasoning=f\"Parse error: {e}\\nRaw: {raw_content}\", accept=False\n",
        "        )\n",
        "\n",
        "\n",
        "class ProjectTrajectory(art.Trajectory):\n",
        "    final_answer: FinalAnswer | None = None\n",
        "\n",
        "\n",
        "class EmailScenario(BaseModel):\n",
        "    step: int\n",
        "    scenario: Scenario\n",
        "\n",
        "\n",
        "@weave.op\n",
        "async def rollout(model: art.Model, email_scenario: EmailScenario) -> ProjectTrajectory:\n",
        "    scenario = email_scenario.scenario\n",
        "\n",
        "    traj = ProjectTrajectory(\n",
        "        reward=0.0,\n",
        "        messages_and_choices=[],\n",
        "        metadata={\n",
        "            \"scenario_id\": scenario.id,\n",
        "            \"step\": email_scenario.step,\n",
        "        },\n",
        "    )\n",
        "\n",
        "    system_prompt = dedent(\n",
        "        f\"\"\"\n",
        "        You are an email search agent. You are given a user query and a list of tools you can use to search the user's email. Use the tools to search the user's emails and find the answer to the user's query. You may take up to {MAX_TURNS} turns to find the answer, so if your first search doesn't find the answer, you can try with different keywords.\n",
        "\n",
        "        User's email address is {scenario.inbox_address}\n",
        "        Today's date is {scenario.query_date}\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    traj.messages_and_choices = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": scenario.question},\n",
        "    ]\n",
        "\n",
        "    def search_inbox(keywords: list[str]) -> list[dict]:\n",
        "        \"\"\"Search the inbox for emails matching the given keywords and return\n",
        "        a list of dictionaries so the LLM can easily consume them.\"\"\"\n",
        "        results = search_emails(\n",
        "            inbox=scenario.inbox_address,\n",
        "            keywords=keywords,\n",
        "            sent_before=scenario.query_date,\n",
        "        )\n",
        "        return [asdict(result) for result in results]\n",
        "\n",
        "    def return_final_answer(\n",
        "        answer: str, reference_message_ids: list[str]\n",
        "    ) -> FinalAnswer:\n",
        "        \"\"\"Return the final answer and the message IDs of the emails that were used to generate the answer.\"\"\"\n",
        "        return FinalAnswer(answer=answer, source_ids=reference_message_ids)\n",
        "\n",
        "    tools = [search_inbox, read_email, return_final_answer]\n",
        "    tools_by_name = {t.__name__: t for t in tools}\n",
        "    traj.tools = [convert_to_openai_tool(t) for t in tools]\n",
        "\n",
        "    if model.trainable:\n",
        "        litellm_model_name = f\"hosted_vllm/{model.name}\"\n",
        "    else:\n",
        "        litellm_model_name = model.name\n",
        "\n",
        "    for _ in range(MAX_TURNS):\n",
        "        response = await acompletion(\n",
        "            model=litellm_model_name,\n",
        "            base_url=model.inference_base_url,\n",
        "            api_key=model.inference_api_key,\n",
        "            temperature=1,\n",
        "            messages=traj.messages(),\n",
        "            caching=False,\n",
        "            tools=traj.tools,\n",
        "        )\n",
        "\n",
        "        response_message = response.choices[0].message\n",
        "        traj.messages_and_choices.append(\n",
        "            convert_litellm_choice_to_openai(response.choices[0])\n",
        "        )\n",
        "\n",
        "        if not response_message.tool_calls:\n",
        "            return traj\n",
        "\n",
        "        try:\n",
        "            for tool_call in response_message.tool_calls:\n",
        "                tool_name: str = tool_call.function.name\n",
        "                if tool_name in tools_by_name:\n",
        "                    tool_args = json.loads(tool_call.function.arguments)\n",
        "                    tool_to_call = tools_by_name[tool_name]\n",
        "                    result = tool_to_call(**tool_args)\n",
        "                    traj.messages_and_choices.append(\n",
        "                        {\n",
        "                            \"role\": \"tool\",\n",
        "                            \"tool_call_id\": tool_call.id,\n",
        "                            \"name\": tool_name,\n",
        "                            \"content\": str(result),\n",
        "                        }\n",
        "                    )\n",
        "\n",
        "                    if tool_name == \"return_final_answer\":\n",
        "                        traj.final_answer = result\n",
        "                        # Score the trajectory\n",
        "                        if traj.final_answer:\n",
        "                            correctness_judge_response = await judge_correctness(\n",
        "                                scenario, traj.final_answer.answer\n",
        "                            )\n",
        "                            traj.metrics[\"correct\"] = float(\n",
        "                                correctness_judge_response.accept\n",
        "                            )\n",
        "                        return traj\n",
        "        except Exception as e:\n",
        "            print(f\"Error parsing tool calls: {e}\")\n",
        "            return traj\n",
        "\n",
        "    return traj\n",
        "\n",
        "\n",
        "print(\"Rollout function defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5q4ayowKBJx"
      },
      "source": [
        "<a name=\"ruler\"></a>\n",
        "\n",
        "### How RULER works\n",
        "\n",
        "**RULER** leverages two key insights:\n",
        "\n",
        "1. Relative scoring is easier than absolute scoring: It's easier for an LLM to rank several solutions relative to each other than to score them in isolation\n",
        "2. GRPO only needs relative scores: Since GRPO normalizes scores within each group, only the relative rankings matter, not absolute values\n",
        "\n",
        "The process:\n",
        "\n",
        "1. Generate N trajectories for a given scenario\n",
        "2. Pass all N trajectories to **RULER**\n",
        "3. **RULER** deduplicates common prefixes (e.g., identical system messages)\n",
        "4. An LLM judge scores each trajectory from 0 to 1 based on goal achievement\n",
        "5. These scores are used directly as rewards in GRPO training\n",
        "\n",
        "To learn more about **RULER**, check out the [RULER docs](https://art.openpipe.ai/fundamentals/ruler).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F45EWPWEKBJx",
        "outputId": "a9d18543-dbb6-4c00-f302-bc3f4d79752a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>RULER<span style=\"font-weight: bold\">]</span> Pretty-printed LLM choice JSON:\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0mRULER\u001b[1m]\u001b[0m Pretty-printed LLM choice JSON:\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'scores'</span>: <span style=\"font-weight: bold\">[</span>\n",
              "        <span style=\"font-weight: bold\">{</span>\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'trajectory_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1'</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'explanation'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Correctly counts to 10 using numeric symbols as specified by the system.'</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>\n",
              "        <span style=\"font-weight: bold\">}</span>,\n",
              "        <span style=\"font-weight: bold\">{</span>\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'trajectory_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2'</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'explanation'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Counts to 10 but uses words instead of numeric symbols, so partially meets the goal.'</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>\n",
              "        <span style=\"font-weight: bold\">}</span>,\n",
              "        <span style=\"font-weight: bold\">{</span>\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'trajectory_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'3'</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'explanation'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Does not count numbers at all, listing letters instead.'</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>\n",
              "        <span style=\"font-weight: bold\">}</span>\n",
              "    <span style=\"font-weight: bold\">]</span>\n",
              "<span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m{\u001b[0m\n",
              "    \u001b[32m'scores'\u001b[0m: \u001b[1m[\u001b[0m\n",
              "        \u001b[1m{\u001b[0m\n",
              "            \u001b[32m'trajectory_id'\u001b[0m: \u001b[32m'1'\u001b[0m,\n",
              "            \u001b[32m'explanation'\u001b[0m: \u001b[32m'Correctly counts to 10 using numeric symbols as specified by the system.'\u001b[0m,\n",
              "            \u001b[32m'score'\u001b[0m: \u001b[1;36m1.0\u001b[0m\n",
              "        \u001b[1m}\u001b[0m,\n",
              "        \u001b[1m{\u001b[0m\n",
              "            \u001b[32m'trajectory_id'\u001b[0m: \u001b[32m'2'\u001b[0m,\n",
              "            \u001b[32m'explanation'\u001b[0m: \u001b[32m'Counts to 10 but uses words instead of numeric symbols, so partially meets the goal.'\u001b[0m,\n",
              "            \u001b[32m'score'\u001b[0m: \u001b[1;36m0.5\u001b[0m\n",
              "        \u001b[1m}\u001b[0m,\n",
              "        \u001b[1m{\u001b[0m\n",
              "            \u001b[32m'trajectory_id'\u001b[0m: \u001b[32m'3'\u001b[0m,\n",
              "            \u001b[32m'explanation'\u001b[0m: \u001b[32m'Does not count numbers at all, listing letters instead.'\u001b[0m,\n",
              "            \u001b[32m'score'\u001b[0m: \u001b[1;36m0.0\u001b[0m\n",
              "        \u001b[1m}\u001b[0m\n",
              "    \u001b[1m]\u001b[0m\n",
              "\u001b[1m}\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Rank 1: Score 1.000\n",
            "  Response: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10...\n",
            "\n",
            "Rank 2: Score 0.500\n",
            "  Response: one, two, three, four, five, six, seven, eight, ni...\n",
            "\n",
            "Rank 3: Score 0.000\n",
            "  Response: a, b, c, d, e, f, g, h, i, j...\n"
          ]
        }
      ],
      "source": [
        "import art\n",
        "from art.rewards import ruler_score_group\n",
        "\n",
        "# Test RULER with a simple example\n",
        "base_messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You count numbers using numeric symbols.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Count to 10.\"},\n",
        "]\n",
        "\n",
        "good_trajectory = art.Trajectory(\n",
        "    messages_and_choices=[\n",
        "        *base_messages,\n",
        "        {\"role\": \"assistant\", \"content\": \"1, 2, 3, 4, 5, 6, 7, 8, 9, 10\"},\n",
        "    ],\n",
        "    reward=0,\n",
        ")\n",
        "\n",
        "mediocre_trajectory = art.Trajectory(\n",
        "    messages_and_choices=[\n",
        "        *base_messages,\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": \"one, two, three, four, five, six, seven, eight, nine, ten\",\n",
        "        },\n",
        "    ],\n",
        "    reward=0,\n",
        ")\n",
        "\n",
        "bad_trajectory = art.Trajectory(\n",
        "    messages_and_choices=[\n",
        "        *base_messages,\n",
        "        {\"role\": \"assistant\", \"content\": \"a, b, c, d, e, f, g, h, i, j\"},\n",
        "    ],\n",
        "    reward=0,\n",
        ")\n",
        "\n",
        "sample_group = art.TrajectoryGroup(\n",
        "    trajectories=[\n",
        "        good_trajectory,\n",
        "        mediocre_trajectory,\n",
        "        bad_trajectory,\n",
        "    ]\n",
        ")\n",
        "\n",
        "judged_group = await ruler_score_group(sample_group, \"openai/o4-mini\", debug=True)\n",
        "assert judged_group is not None\n",
        "\n",
        "# Display rankings\n",
        "sorted_trajectories = sorted(\n",
        "    judged_group.trajectories, key=lambda t: t.reward, reverse=True\n",
        ")\n",
        "for rank, traj in enumerate(sorted_trajectories, 1):\n",
        "    messages = traj.messages()\n",
        "    print(f\"\\nRank {rank}: Score {traj.reward:.3f}\")\n",
        "    print(f\"  Response: {messages[-1]['content'][:50]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnWEOEuKKBJy"
      },
      "source": [
        "<a name=\"Loop\"></a>\n",
        "\n",
        "### Training Loop\n",
        "\n",
        "The training loop is where the magic happens. For each of the 10 steps defined below, the rollout function will be called multiple times in parallel. Each scenario will produce a trajectory, which will be used to update the model.\n",
        "\n",
        "The `gather` step will wait for all of the trajectories to be generated, then it will use RULER to assign relative scores to each trajectory.\n",
        "\n",
        "Our notebook will then delete all but the most recent checkpoint and train the model on the scored trajectories.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oerzbTmYKBJy"
      },
      "outputs": [],
      "source": [
        "# Training configuration\n",
        "from art.utils import iterate_dataset\n",
        "\n",
        "training_config = {\n",
        "    \"groups_per_step\": 2,\n",
        "    \"num_epochs\": 20,\n",
        "    \"rollouts_per_group\": 4,\n",
        "    \"learning_rate\": 1e-5,\n",
        "    \"max_steps\": 20,\n",
        "}\n",
        "\n",
        "# Use iterate_dataset with real training scenarios (similar to train.py)\n",
        "training_iterator = iterate_dataset(\n",
        "    training_scenarios,  # Use real scenarios from Hugging Face\n",
        "    groups_per_step=training_config[\"groups_per_step\"],\n",
        "    num_epochs=training_config[\"num_epochs\"],\n",
        "    initial_step=await model.get_step(),\n",
        ")\n",
        "\n",
        "for batch in training_iterator:\n",
        "    print(\n",
        "        f\"Training step {batch.step}, epoch {batch.epoch}, epoch step {batch.epoch_step}\"\n",
        "    )\n",
        "    print(f\"Batch contains {len(batch.items)} scenarios\")\n",
        "\n",
        "    # Create trajectory groups for this batch (similar to train.py)\n",
        "    groups = []\n",
        "    for scenario in batch.items:\n",
        "        groups.append(\n",
        "            art.TrajectoryGroup(\n",
        "                (\n",
        "                    rollout(model, EmailScenario(step=batch.step, scenario=scenario))\n",
        "                    for _ in range(training_config[\"rollouts_per_group\"])\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # Gather all trajectory groups\n",
        "    finished_groups = await art.gather_trajectory_groups(\n",
        "        groups,\n",
        "        pbar_desc=\"gather\",\n",
        "        max_exceptions=training_config[\"rollouts_per_group\"] * len(batch.items),\n",
        "    )\n",
        "\n",
        "    judged_groups = []\n",
        "    for group in finished_groups:\n",
        "        # Use RULER to assign relative scores to each trajectory\n",
        "        judged_group = await ruler_score_group(group, \"openai/o4-mini\", debug=True)\n",
        "        judged_groups.append(judged_group)\n",
        "\n",
        "    await model.delete_checkpoints()\n",
        "    await model.train(\n",
        "        judged_groups,\n",
        "        config=art.TrainConfig(learning_rate=training_config[\"learning_rate\"]),\n",
        "        # Lowering the logprob_calculation_chunk_size is a memory saving measure\n",
        "        # to allow longer sequences (up to 8192 tokens) to be processed on a T4.\n",
        "        _config={\"logprob_calculation_chunk_size\": 8},\n",
        "    )\n",
        "\n",
        "    print(f\"Completed training step {batch.step}\")\n",
        "\n",
        "    # Stop after max_steps for demo purposes (adjust as needed)\n",
        "    if batch.step >= training_config[\"max_steps\"]:\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDDVlMIhKBJy"
      },
      "source": [
        "### Using the Model\n",
        "\n",
        "Just like that, you've trained an agent to search emails and answer questions! Now it's time to use your model outside of the training loop.\n",
        "\n",
        "Check out the code below for a small demo of the model you just trained!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7S2L3DaKBJy"
      },
      "outputs": [],
      "source": [
        "# Test the trained model using the rollout function\n",
        "# This avoids memory issues and uses the same inference path as training\n",
        "\n",
        "print(\"Testing the trained model with a real scenario...\\n\")\n",
        "\n",
        "\n",
        "# Use a scenario from our training set\n",
        "test_scenario = training_scenarios[1]\n",
        "\n",
        "print(f\"Test scenario ID: {test_scenario.id}\")\n",
        "print(f\"Question: {test_scenario.question}\")\n",
        "print(f\"Expected answer: {test_scenario.answer}\")\n",
        "print(f\"Reference message IDs: {test_scenario.message_ids}\")\n",
        "print(f\"Inbox: {test_scenario.inbox_address}\")\n",
        "print(f\"Query date: {test_scenario.query_date}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Run the rollout function with the trained model\n",
        "test_email_scenario = EmailScenario.model_validate(\n",
        "    {\"step\": 0, \"scenario\": test_scenario.model_dump()}\n",
        ")\n",
        "result_trajectory = await rollout(model, test_email_scenario)\n",
        "\n",
        "print(\"Agent's trajectory:\")\n",
        "print(\"-\" * 20)\n",
        "\n",
        "# Display the conversation\n",
        "messages = result_trajectory.messages()\n",
        "for i, msg in enumerate(messages):\n",
        "    role = msg.get(\"role\", \"unknown\")\n",
        "    content = msg.get(\"content\", \"\")\n",
        "    tool_calls = msg.get(\"tool_calls\", [])\n",
        "\n",
        "    if role == \"system\":\n",
        "        print(\n",
        "            f\"[SYSTEM]: {content[:100]}...\"\n",
        "            if len(content) > 100\n",
        "            else f\"[SYSTEM]: {content}\"\n",
        "        )\n",
        "    elif role == \"user\":\n",
        "        print(f\"[USER]: {content}\")\n",
        "    elif role == \"assistant\":\n",
        "        if tool_calls:\n",
        "            print(f\"[ASSISTANT]: {tool_calls}\")\n",
        "        if content:\n",
        "            print(f\"[ASSISTANT]: {content}\")\n",
        "    elif role == \"tool\":\n",
        "        tool_name = msg.get(\"name\", \"unknown_tool\")\n",
        "        print(\n",
        "            f\"[TOOL - {tool_name}]: {content[:200]}...\"\n",
        "            if len(content) > 200\n",
        "            else f\"[TOOL - {tool_name}]: {content}\"\n",
        "        )\n",
        "\n",
        "    print()\n",
        "\n",
        "print(\"-\" * 50)\n",
        "if result_trajectory.final_answer:\n",
        "    print(f\"Agent's Final Answer: {result_trajectory.final_answer.answer}\")\n",
        "    print(f\"Source IDs Used: {result_trajectory.final_answer.source_ids}\")\n",
        "else:\n",
        "    print(\"No final answer provided by the agent\")\n",
        "\n",
        "print(f\"\\nExpected Answer: {test_scenario.answer}\")\n",
        "print(f\"Expected Source IDs: {test_scenario.message_ids}\")\n",
        "\n",
        "print(\"\\n🎉 Email search agent testing completed!\")\n",
        "print(\n",
        "    \"The agent used the same inference path as during training, avoiding memory issues.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Q2sUzTEKBJy"
      },
      "source": [
        "<div class=\"align-center\">\n",
        "<a href=\"https://github.com/openpipe/art\"><img src=\"https://github.com/openpipe/art/raw/main/assets/ART_pill.png\" height=\"50\"></a>\n",
        "<a href=\"https://discord.gg/zbBHRUpwf4\"><img src=\"https://github.com/openpipe/art/raw/main/assets/Discord_pill.png\" height=\"50\"></a>\n",
        "<a href=\"https://art.openpipe.ai\"><img src=\"https://github.com/openpipe/art/raw/main/assets/Documentation_pill.png\" height=\"50\"></a>\n",
        "\n",
        "Questions? Join the Discord and ask away! For feature requests or to leave a star, visit our [Github](https://github.com/openpipe/art).\n",
        "\n",
        "</div>\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "58fdaec5ad8745929830387d20e8397e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51dd537611d4445b88d139b66fe2c4a2",
              "IPY_MODEL_00d7f424a59349fb8d8fe0bcf0bd7102",
              "IPY_MODEL_cc4430035a0545c9a800db300d91a174"
            ],
            "layout": "IPY_MODEL_3d09c6c630484dec915552689ba69663"
          }
        },
        "51dd537611d4445b88d139b66fe2c4a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54c0e051ce1f4fd6972ebdfe4e8ae08d",
            "placeholder": "​",
            "style": "IPY_MODEL_e97ba0da9e334134a979be6972b41a04",
            "value": "README.md: 100%"
          }
        },
        "00d7f424a59349fb8d8fe0bcf0bd7102": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d62dea2c92534b63b0df7a91b6680d63",
            "max": 631,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69e9984702ff4cceb6c7cd55edf38860",
            "value": 631
          }
        },
        "cc4430035a0545c9a800db300d91a174": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65a7f6895ffa4174831c9fc2063b24ed",
            "placeholder": "​",
            "style": "IPY_MODEL_f22b78db8a3c422b836f4f443c81f6a5",
            "value": " 631/631 [00:00&lt;00:00, 23.2kB/s]"
          }
        },
        "3d09c6c630484dec915552689ba69663": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54c0e051ce1f4fd6972ebdfe4e8ae08d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e97ba0da9e334134a979be6972b41a04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d62dea2c92534b63b0df7a91b6680d63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69e9984702ff4cceb6c7cd55edf38860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "65a7f6895ffa4174831c9fc2063b24ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f22b78db8a3c422b836f4f443c81f6a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9e872fa3ca14db9bca2463bdca3b41f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cad5bee991074396a6cfc434500ebd91",
              "IPY_MODEL_d0022cb132e4474c8e40aaadfd71fb3c",
              "IPY_MODEL_f991f8de175c46c0ac25fbef442c4c98"
            ],
            "layout": "IPY_MODEL_4f1c119128644809a2f9fd92c824a383"
          }
        },
        "cad5bee991074396a6cfc434500ebd91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_271cd7d4207340e4938b3ee12e889add",
            "placeholder": "​",
            "style": "IPY_MODEL_b763df2591004561ad582d7b00feb6f4",
            "value": "train-00000-of-00001.parquet: 100%"
          }
        },
        "d0022cb132e4474c8e40aaadfd71fb3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_117b3eadcd78492085a37b821dd64579",
            "max": 681490,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_55c5fae124154ed68bb64d7023032604",
            "value": 681490
          }
        },
        "f991f8de175c46c0ac25fbef442c4c98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_402f5ace992147b0a09e21e122a0609d",
            "placeholder": "​",
            "style": "IPY_MODEL_f9a2416c5bf44d1b938a44eb52874f5a",
            "value": " 681k/681k [00:00&lt;00:00, 1.58MB/s]"
          }
        },
        "4f1c119128644809a2f9fd92c824a383": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "271cd7d4207340e4938b3ee12e889add": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b763df2591004561ad582d7b00feb6f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "117b3eadcd78492085a37b821dd64579": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55c5fae124154ed68bb64d7023032604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "402f5ace992147b0a09e21e122a0609d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9a2416c5bf44d1b938a44eb52874f5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80a8753a4ce74f4e8cbc419dd2b4cfb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b986665f2a424a399bdc50c5a1d6f9a2",
              "IPY_MODEL_6294c4d7db0c4446bfbe870b1fb00663",
              "IPY_MODEL_34ebb3bd161c400b8686b166838de5fa"
            ],
            "layout": "IPY_MODEL_c640c8620bb244708a5f26423059de6b"
          }
        },
        "b986665f2a424a399bdc50c5a1d6f9a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94fdc195922643759f0cdd589d6fec60",
            "placeholder": "​",
            "style": "IPY_MODEL_d463ac615ede4edb8eb9ec83746f66da",
            "value": "test-00000-of-00001.parquet: 100%"
          }
        },
        "6294c4d7db0c4446bfbe870b1fb00663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02b2e89be06c40e79024dc8a88272d19",
            "max": 267520,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b2ea09cf684944cf83dd980105a13518",
            "value": 267520
          }
        },
        "34ebb3bd161c400b8686b166838de5fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fb55d6ec4774e698ef689711e3fe394",
            "placeholder": "​",
            "style": "IPY_MODEL_b53c2a30d50b4fea9b8fa9cb443f669c",
            "value": " 268k/268k [00:00&lt;00:00, 11.6MB/s]"
          }
        },
        "c640c8620bb244708a5f26423059de6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94fdc195922643759f0cdd589d6fec60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d463ac615ede4edb8eb9ec83746f66da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02b2e89be06c40e79024dc8a88272d19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2ea09cf684944cf83dd980105a13518": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8fb55d6ec4774e698ef689711e3fe394": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b53c2a30d50b4fea9b8fa9cb443f669c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d654feb8c837413d9e2eed3d0c05c29e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d725e8f396943919db3132bc4f0dcd4",
              "IPY_MODEL_acbff660bb2c4ce3bfbea69736c520c8",
              "IPY_MODEL_8d14909d1bd04100ae917ba0bb938597"
            ],
            "layout": "IPY_MODEL_0872d4d7e6074875983ce1e6f16e02db"
          }
        },
        "2d725e8f396943919db3132bc4f0dcd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_292ddab707b6473795ab6e0471da4ad4",
            "placeholder": "​",
            "style": "IPY_MODEL_7e4ea1fb7d8b431b97b67bf31e9fa639",
            "value": "Generating train split: 100%"
          }
        },
        "acbff660bb2c4ce3bfbea69736c520c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4d214dbbd8a41bda05094c0a7a840bb",
            "max": 4390,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b822452a3aca49f1825569859a69d684",
            "value": 4390
          }
        },
        "8d14909d1bd04100ae917ba0bb938597": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d88ec76b677143d48fd043183d6a34ae",
            "placeholder": "​",
            "style": "IPY_MODEL_56256df39f0349868d36bfc56eebf065",
            "value": " 4390/4390 [00:00&lt;00:00, 65936.37 examples/s]"
          }
        },
        "0872d4d7e6074875983ce1e6f16e02db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "292ddab707b6473795ab6e0471da4ad4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e4ea1fb7d8b431b97b67bf31e9fa639": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4d214dbbd8a41bda05094c0a7a840bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b822452a3aca49f1825569859a69d684": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d88ec76b677143d48fd043183d6a34ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56256df39f0349868d36bfc56eebf065": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afab869005ee43cebe5c509ca96e3102": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cdfa9c8b41db4196adf6c160479cd307",
              "IPY_MODEL_b35821ae04964dc1991c1ca8dd1b888b",
              "IPY_MODEL_b2289aa5d03a4e02984b00917fde90ad"
            ],
            "layout": "IPY_MODEL_2fc3e08aa6394355a22d600d1fc28d9b"
          }
        },
        "cdfa9c8b41db4196adf6c160479cd307": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_023c6b7d19564faa84a9fd572ad0e98c",
            "placeholder": "​",
            "style": "IPY_MODEL_a65e7289aec743a4ab276127421f64dd",
            "value": "Generating test split: 100%"
          }
        },
        "b35821ae04964dc1991c1ca8dd1b888b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a6300db73444b1e8965fd01465ccc51",
            "max": 1733,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7896eb432ed445cfb93f3633058ebe63",
            "value": 1733
          }
        },
        "b2289aa5d03a4e02984b00917fde90ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e95330d012f4717b66331d4dbf212e7",
            "placeholder": "​",
            "style": "IPY_MODEL_6c3a9ceb5d994e1ba844743767387f37",
            "value": " 1733/1733 [00:00&lt;00:00, 52368.74 examples/s]"
          }
        },
        "2fc3e08aa6394355a22d600d1fc28d9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "023c6b7d19564faa84a9fd572ad0e98c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a65e7289aec743a4ab276127421f64dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a6300db73444b1e8965fd01465ccc51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7896eb432ed445cfb93f3633058ebe63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e95330d012f4717b66331d4dbf212e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c3a9ceb5d994e1ba844743767387f37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5422e8503d18440d908b78774f6d5100": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1298ae38917943049faef93c825f3023",
              "IPY_MODEL_4acd820779de427a8b85a41987d813e5",
              "IPY_MODEL_c94d4039ea0b4195964d90cef0ecda3e"
            ],
            "layout": "IPY_MODEL_e3c358c0690b45118b84d0e5c13634a1"
          }
        },
        "1298ae38917943049faef93c825f3023": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f885b1d9df4b4c13876c5520756c0e9b",
            "placeholder": "​",
            "style": "IPY_MODEL_13bb10e53c124257ac90f6da4cf1b569",
            "value": "Filter: 100%"
          }
        },
        "4acd820779de427a8b85a41987d813e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4828d19db19b448b87cebf2e79722c9f",
            "max": 4390,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6c1f31583c54400fb00ebfb2494f3389",
            "value": 4390
          }
        },
        "c94d4039ea0b4195964d90cef0ecda3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58ce69dd46a648bb9d0e763a62175cc6",
            "placeholder": "​",
            "style": "IPY_MODEL_cf906ce5311e4859af04a2965f453e13",
            "value": " 4390/4390 [00:00&lt;00:00, 53857.59 examples/s]"
          }
        },
        "e3c358c0690b45118b84d0e5c13634a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f885b1d9df4b4c13876c5520756c0e9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13bb10e53c124257ac90f6da4cf1b569": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4828d19db19b448b87cebf2e79722c9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c1f31583c54400fb00ebfb2494f3389": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "58ce69dd46a648bb9d0e763a62175cc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf906ce5311e4859af04a2965f453e13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}